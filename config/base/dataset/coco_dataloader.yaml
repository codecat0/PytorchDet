sample_transforms:
  - _target_: det.data.transform.operators.Decode
  - _target_: det.data.transform.operators.RandomFlip
    prob: 0.5
  - _target_: det.data.transform.operators.RandomSelect
    transforms1:
      - _target_: det.data.transform.operators.RandomShortSideResize
        short_side_sizes:
          - 480
          - 512
          - 544
          - 576
          - 608
          - 640
          - 672
          - 704
          - 736
          - 768
          - 800
        max_size: 1333
    transforms2:
      - _target_: det.data.transform.operators.RandomShortSideResize
        short_side_sizes:
          - 400
          - 500
          - 600
      - _target_: det.data.transform.operators.RandomSizeCrop
        min_size: 384
        max_size: 600
      - _target_: det.data.transform.operators.RandomShortSideResize
        short_side_sizes:
          - 480
          - 512
          - 544
          - 576
          - 608
          - 640
          - 672
          - 704
          - 736
          - 768
          - 800
  - _target_: det.data.transform.operators.NormalizeImage
    is_scale: true
    mean:
      - 0.485
      - 0.456
      - 0.406
    std:
      - 0.229
      - 0.224
      - 0.225
  - _target_: det.data.transform.operators.NormalizeBox
  - _target_: det.data.transform.operators.BboxXYXY2XYWH
  - _target_: det.data.transform.operators.Permute

batch_transforms:
  - _target_: det.data.transform.batch_operators.PadMaskBatch
    pad_to_stride: -1
    return_pad_mask: true

dataloader:
  _target_: det.data.reader.TrainReader
  sample_transforms: ${sample_transforms}
  batch_transforms: ${batch_transforms}
  batch_size: 2
  shuffle: true
  drop_last: true
  collate_batch: false

worker_num: 0

dataset:
  _target_: det.data.source.coco.COCODataset
  dataset_dir: '/data0/helizhi/works/PytorchDet/data'
  image_dir: 'train'
  anno_path: 'annotations/instance_train.json'
  data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

