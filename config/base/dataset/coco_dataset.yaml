sample_transforms_lst:
  - _target_: det.data.transform.operators.Decode
  - _target_: det.data.transform.operators.RandomFlip
    prob: 0.5
  - _target_: det.data.transform.operators.RandomSelect
    transforms1:
      - _target_: det.data.transform.operators.RandomShortSideResize
        short_side_sizes:
          - 480
          - 512
          - 544
          - 576
          - 608
          - 640
          - 672
          - 704
          - 736
          - 768
          - 800
        max_size: 1333
    transforms2:
      - _target_: det.data.transform.operators.RandomShortSideResize
        short_side_sizes:
          - 400
          - 500
          - 600
      - _target_: det.data.transform.operators.RandomSizeCrop
        min_size: 384
        max_size: 600
      - _target_: det.data.transform.operators.RandomShortSideResize
        short_side_sizes:
          - 480
          - 512
          - 544
          - 576
          - 608
          - 640
          - 672
          - 704
          - 736
          - 768
          - 800
  - _target_: det.data.transform.operators.NormalizeImage
    is_scale: true
    mean:
      - 0.485
      - 0.456
      - 0.406
    std:
      - 0.229
      - 0.224
      - 0.225
  - _target_: det.data.transform.operators.NormalizeBox
  - _target_: det.data.transform.operators.BboxXYXY2XYWH
  - _target_: det.data.transform.operators.Permute


sample_transforms:
  _target_: det.data.reader.Compose
  transforms: ${sample_transforms_lst}
  num_classes: 1


dataset:
  _target_: det.data.source.coco.COCODataset
  dataset_dir: '/data0/helizhi/works/PytorchDet/data'
  image_dir: 'train'
  anno_path: 'annotations/instance_train.json'
  data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']